
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.18">
    
    
      
        <title>Legacy - AutoML Benchmark</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.26e3688c.min.css">
      
      
  
  
    
    
  
  
  <style>:root{--md-admonition-icon--windows:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="m0 93.7 183.6-25.3v177.4H0V93.7zm0 324.6 183.6 25.3V268.4H0v149.9zm203.8 28L448 480V268.4H203.8v177.9zm0-380.6v180.1H448V32L203.8 65.7z"/></svg>');}</style>


    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#add-a-benchmark" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../index.html" title="AutoML Benchmark" class="md-header__button md-logo" aria-label="AutoML Benchmark" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8h5Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AutoML Benchmark
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Legacy
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="AutoML Benchmark" class="md-nav__button md-logo" aria-label="AutoML Benchmark" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20v-6h4v6h5v-8h3L12 3 2 12h3v8h5Z"/></svg>

    </a>
    AutoML Benchmark
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        AutoML Benchmark
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/" class="md-nav__link">
        Getting Started
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
      
      
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
          Using the Benchmark
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Using the Benchmark
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../using/parameters/" class="md-nav__link">
        Parameters
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../using/configuration/" class="md-nav__link">
        Configuration
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../using/aws/" class="md-nav__link">
        AWS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../using/result_analysis/" class="md-nav__link">
        Results
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
        
      
      <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
      
      
        
          
            
          
        
          
        
          
        
          
        
      
      
        
        
        <div class="md-nav__link md-nav__link--index ">
          <a href="../extending/">Extending the Benchmark</a>
          
            <label for="__nav_4">
              <span class="md-nav__icon md-icon"></span>
            </label>
          
        </div>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Extending the Benchmark
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../extending/benchmark/" class="md-nav__link">
        Benchmark
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../extending/constraint/" class="md-nav__link">
        Constraints
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../extending/framework/" class="md-nav__link">
        Frameworks
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../faq/" class="md-nav__link">
        FAQ
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#add-a-benchmark" class="md-nav__link">
    Add a benchmark
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#troubleshooting-guide" class="md-nav__link">
    Troubleshooting guide
  </a>
  
    <nav class="md-nav" aria-label="Troubleshooting guide">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#where-are-the-results" class="md-nav__link">
    Where are the results?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#where-are-the-logs" class="md-nav__link">
    Where are the logs?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#profiling-the-application" class="md-nav__link">
    Profiling the application
  </a>
  
    <nav class="md-nav" aria-label="Profiling the application">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#memory-usage" class="md-nav__link">
    Memory usage
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#methods-duration" class="md-nav__link">
    Methods duration
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#python-library-version-conflict" class="md-nav__link">
    Python library version conflict
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-setup-is-not-executed" class="md-nav__link">
    Framework setup is not executed
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#framework-setup-fails" class="md-nav__link">
    Framework setup fails
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  <h1>Legacy</h1>

<h2 id="add-a-benchmark">Add a benchmark</h2>
<p>In this section, <code>benchmark</code> means a suite of datasets that can be used to feed any of the available frameworks, in combination with a set of constraints (time limit, cpus, memory) enforced by the application.</p>
<p>A benchmark definition will then consist in a <a href="#datasets-definition">datasets definition</a> and a <a href="#constraint-definition">constraints definition</a>.</p>
<p>Each dataset must contain a training set and a test set. There can be multiple training/test splits, in which case each split is named a <code>fold</code>, so that the same dataset can be benchmarked multiple times using a different fold.</p>
<p>or using pyenv:
<div class="language-bash highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>pyenv<span class="w"> </span>install<span class="w"> </span><span class="o">{</span>python_version:<span class="w"> </span><span class="m">3</span>.9.16<span class="o">}</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>pyenv<span class="w"> </span>virtualenv<span class="w"> </span>ve-automl
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>pyenv<span class="w"> </span><span class="nb">local</span><span class="w"> </span>ve-automl
</span></code></pre></div></p>
<ul>
<li><em><strong>NOTE</strong>: in case of issues when installing Python requirements, you may want to try the following:</em><ul>
<li><em>on some platforms, we need to ensure that requirements are installed sequentially:</em> <code>xargs -L 1 python -m pip install &lt; requirements.txt</code>.</li>
<li><em>enforce the <code>python -m pip</code> version above in your virtualenv:</em> <code>python -m pip install --upgrade pip==19.3.1</code>.</li>
</ul>
</li>
</ul>
<h2 id="troubleshooting-guide">Troubleshooting guide</h2>
<h3 id="where-are-the-results">Where are the results?</h3>
<p>By default, the results for a benchmark execution are made available in a subfolder under <code>output_dir</code> (if not specified by <code>-o my_results</code>, then this is under <code>{cwd}/results</code>).</p>
<p>This subfolder is named <code>{framework}_{benchmark}_{constraint}_{mode}_{timestamp}</code>.</p>
<p>So that for example:
<div class="language-bash highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>python<span class="w"> </span>runbenchmark.py<span class="w"> </span>randomforest
</span></code></pre></div>
will create a subfolder <code>randomforest_test_test_local_20200108T184305</code>,</p>
<p>and:
<div class="language-bash highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>python<span class="w"> </span>runbenchmark.py<span class="w"> </span>randomforest<span class="w"> </span>validation<span class="w"> </span>1h4c<span class="w"> </span>-m<span class="w"> </span>aws
</span></code></pre></div>
will create a subfolder <code>randomforest_validation_1h4c_aws_20200108T184305</code>.</p>
<p>Then each subfolder contains:
 - a <code>score</code> folder with a <code>results.csv</code> file concatenating the results from all the tasks in the benchmark, as well as potentially other individual results for each task.<br />
 - a <code>predictions</code> folder with the predictions for each task in the benchmark.
 - a <code>logs</code> folder: only if benchmark was executed with <code>-o output_dir</code> argument.
 - possibly more folders if the framework saves additional artifacts.</p>
<p>Also the <code>output_dir</code> contains a <code>results.csv</code> concatenating <strong>ALL results</strong> from all subfolders.</p>
<h3 id="where-are-the-logs">Where are the logs?</h3>
<p>By default the application logs are available under <code>{cwd}/logs</code> if the benchmark is executed without specifying the <code>output_dir</code>, otherwise, they'll be available under the <code>logs</code> subfolder in the benchmark results (see <a href="#where-are-the-results">Where are the results?</a>).</p>
<p>The application can collect various logs:
- local benchmark application logs: those are always collected. For each run, the application generated 2 log files locally:
  - <code>runbenchmark_{timestamp}.log</code>: contains logs for the application only (from DEBUG level).
  - <code>runbenchmark_{timestamp}_full.log</code>: contains logs for the application + other Python libraries (from INFO level); e.g. <code>boto3</code> logs when running in <code>aws</code> mode.
- remote application logs: for <code>aws</code> mode only, logs generated on the remote instances are automatically downloaded to the results folder, together with other result artifacts. 
- framework logs (optional): if the framework integration supports it, it is possible to ask for the framework logs by creating a custom framework definition as follow:
  <div class="language-yaml highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="nt">H2OAutoML</span><span class="p">:</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="w">  </span><span class="nt">extends</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">H2OAutoML</span>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="w">  </span><span class="nt">params</span><span class="p">:</span>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="w">    </span><span class="nt">_save_artifacts</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="s">&#39;logs&#39;</span><span class="p p-Indicator">]</span>
</span></code></pre></div></p>
<h3 id="profiling-the-application">Profiling the application</h3>
<p>Currently, the application provides a global flag <code>--profiling</code> to activate profiling for some specific methods that can be slow or memory intensive:
<div class="language-bash highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>python<span class="w"> </span>runbenchmark.py<span class="w"> </span>randomforest<span class="w"> </span>--profiling
</span></code></pre></div>
All methods/functions are not profiled, but if you need to profile more, you just need to decorate the function with the <code>@profile()</code> decorator (from <code>amlb.utils</code>).</p>
<h4 id="memory-usage">Memory usage</h4>
<p><em>Examples of memory info when using this custom profiling</em>:
<div class="language-text highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>[PROFILING] `amlb.datasets.openml.OpenmlDatasplit.data` returned object size: 45.756 MB.
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>[PROFILING] `amlb.datasets.openml.OpenmlDatasplit.data` memory change; process: +241.09 MB/379.51 MB, resident: +241.09 MB/418.00 MB, virtual: +230.01 MB/4918.16 MB.
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>...
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>[PROFILING] `amlb.data.Datasplit.release` executed in 0.007s.
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>[PROFILING] `amlb.data.Datasplit.release` memory change; process: -45.73 MB/238.80 MB, resident: +0.00 MB/414.60 MB, virtual: +0.00 MB/4914.25 MB.
</span></code></pre></div></p>
<h4 id="methods-duration">Methods duration</h4>
<p><em>Examples of method duration info when using this custom profiling</em>:
<div class="language-text highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>[PROFILING] `amlb.datasets.openml.OpenmlLoader.load` executed in 7.456s.
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>...
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>[PROFILING] `amlb.data.Datasplit.X_enc` executed in 6.570s.
</span></code></pre></div></p>
<h3 id="python-library-version-conflict">Python library version conflict</h3>
<p>see <a href="#frameworks-requiring-a-dedicated-virtual-env">Framework integration</a></p>
<h3 id="framework-setup-is-not-executed">Framework setup is not executed</h3>
<p>Try the following:
- force the setup using the <code>-s only</code> or <code>-s force</code> arg on the command line:
  - <code>-s only</code> or <code>--setup=only</code> will force the setup and skip the benchmark run.
  - <code>-s force</code> or <code>--setup=force</code> will force the setup and run the benchmark immediately.
- delete the <code>.marker_setup_safe_to_delete</code> from the framework module and try to run the benchmark again. This marker file is automatically created after a successful setup to avoid having to execute it each tine (setup phase can be time-consuming), this marker then prevents auto-setup, except if the <code>-s only</code> or <code>-s force</code> args above are used.</p>
<h3 id="framework-setup-fails">Framework setup fails</h3>
<p>If the setup fails, first note that only the following OS are fully supported:
- Ubuntu 18.04</p>
<p>The setup is created for Debian-based linux environments, and macOS (most frameworks can be installed on macOS, ideally with <code>brew</code> installed, but there may be a few exceptions), so it may work with other Linux environments not listed above (e.g. Debian, Ubuntu 20.04, ...).
The best way to run benchmarks on non-supported OS, is to use the docker mode.</p>
<p>If the setup fails on a supported environment, please try the following:
- force the setup: see above.
- ensure that the same framework is not set up multiple times in parallel on the same machine:
  - first use <code>python runbenchmark.py MyFramework -s only</code> on one terminal.
  - then you can trigger multiple <code>python runbenchmark.py MyFramework ...</code> (without <code>-s</code> option) in parallel.
- delete the <code>lib</code> and <code>venv</code> folders, if present, under the given framework folder (e.g. <code>frameworks/MyFramework</code>), and try the setup again.</p>





                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.expand", "navigation.indexes", "content.tabs.link", "content.code.annotate"], "search": "../assets/javascripts/workers/search.74e28a9f.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.220ee61c.min.js"></script>
      
    
  </body>
</html>